# Package Test Template
#
# This is a TEMPLATE file stored in the tests/ directory - it will not run as a workflow.
# To use it:
# 1. Copy this file to .github/workflows/test-<your-package>.yml
# 2. Replace all Bonjour placeholders with your package name (e.g., "Redis")
# 3. Replace all bonjour placeholders with your package slug (lowercase, e.g., "redis")
# 4. Update the install commands for your package
# 5. Update the version detection command
# 6. Add/modify/remove test steps as needed
# 7. Update package metadata in the JSON generation step
# 8. Uncomment the appropriate trigger(s) in the 'on:' section
#
# See .github/workflows/test-nginx.yml and test-envoy.yml for real examples. Template
#
# This is a TEMPLATE file - it will not run automatically.
# To use it:
# 1. Copy this file to test-<your-package>.yml
# 2. Replace all Bonjour placeholders with your package name (e.g., "Redis")
# 3. Replace all bonjour placeholders with your package slug (lowercase, e.g., "redis")
# 4. Update the install commands for your package
# 5. Update the version detection command
# 6. Add/modify/remove test steps as needed
# 7. Update package metadata in the JSON generation step
# 8. Uncomment the 'push:' trigger section below (remove the workflow_dispatch if desired)
#
# See test-nginx.yml and test-envoy.yml for real examples.

name: Test Bonjour on Arm64

# This is a TEMPLATE - it has no triggers and will not run.
# When you copy this file, uncomment the appropriate triggers below:
on:
  # workflow_dispatch:  # Uncomment for manual testing
  workflow_call:
  push:
    branches:
      - main
      - smoke_tests
    paths:
      - 'content/opensource_packages/bonjour.md'
      - '.github/workflows/test-bonjour.yml'

jobs:
  test-bonjour:
    runs-on: ubuntu-24.04-arm
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      
      - name: Set test metadata
        id: metadata
        run: |
          echo "timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_OUTPUT
          echo "package_slug=bonjour" >> $GITHUB_OUTPUT
          echo "dashboard_link=/opensource_packages/bonjour" >> $GITHUB_OUTPUT
      
      # ============================================================
      # CUSTOMIZE THIS: Install your package
      # ============================================================
      # ============================================================
      # CUSTOMIZE THIS: Install your package
      # ============================================================
      - name: Install Bonjour (Avahi)
        id: install
        run: |
          echo "Installing Bonjour compatibility (Avahi)..."
          
          # Install Avahi tools and compatibility library
          sudo apt-get update
          sudo apt-get install -y libavahi-compat-libdnssd-dev avahi-utils
          
          # Verify installation
          if [ -f "/usr/include/dns_sd.h" ] || command -v avahi-browse &> /dev/null; then
            echo "Bonjour compatibility installed successfully"
            echo "install_status=success" >> $GITHUB_OUTPUT
          else
            echo "Bonjour installation failed"
            echo "install_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
      
      # ============================================================
      # CUSTOMIZE THIS: Get the package version
      # ============================================================
      - name: Get Bonjour/Avahi version
        id: version
        run: |
          # Get avahi usage version
          VERSION=$(avahi-browse --version 2>&1 | awk '{print $2}' || echo "unknown")
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "Detected Bonjour/Avahi version: $VERSION"
      
      # ============================================================
      # ADD YOUR TESTS BELOW
      # ============================================================
      
      - name: Test 1 - Check compatibility headers
        id: test1
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          # dns_sd.h is the Bonjour compatibility header
          if [ -f "/usr/include/dns_sd.h" ]; then
            echo "✓ dns_sd.h found"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ dns_sd.h header not found"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT
      
      - name: Test 2 - Check avahi-utils binary
        id: test2
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          if command -v avahi-browse &> /dev/null; then
            echo "✓ avahi-browse binary found"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ avahi-browse binary not found"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT
      
      - name: Test 3 - Check avahi-browse help output
        id: test3
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          if avahi-browse --help 2>&1 | grep -qi "usage\|help\|options"; then
            echo "✓ avahi-browse help command works"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ avahi-browse help command failed"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT
      
      # Test 4 - Architecture Verification
      - name: Test 4 - Architecture Verification
        id: test4
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          echo "Checking system architecture..."
          ARCH=$(uname -m)
          if [ "$ARCH" = "aarch64" ]; then
            echo "✓ System architecture is ARM64 ($ARCH)"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ System architecture is NOT ARM64 ($ARCH)"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT

      - name: Test 5 - Functional Validation
        id: test5
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          # Basic functional check: try to run a simple discovery check (expected to fail or be empty without daemon, but binary should run)
          # We check return code for 'command not found' (127) vs execution
          if avahi-browse --version > /dev/null 2>&1; then
            echo "✓ Basic functional check passed (binary runs)"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ Basic functional check failed"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

          END_TIME=$(date +%s)
      - name: Calculate test summary
        if: always()
        id: summary
        run: |
          PASSED=0
          FAILED=0
          TOTAL_DURATION=0

          # Check compatibility headers
          if [ "${{ steps.test1.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test1.outputs.duration || 0 }}))

          # Check avahi-utils binary
          if [ "${{ steps.test2.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test2.outputs.duration || 0 }}))

          # Check avahi-browse help output
          if [ "${{ steps.test3.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test3.outputs.duration || 0 }}))

          # Architecture Verification
          if [ "${{ steps.test4.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test4.outputs.duration || 0 }}))

          # Functional Validation
          if [ "${{ steps.test5.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test5.outputs.duration || 0 }}))

          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "duration=$TOTAL_DURATION" >> $GITHUB_OUTPUT

          if [ $FAILED -eq 0 ]; then
            echo "overall_status=success" >> $GITHUB_OUTPUT
            echo "badge_status=passing" >> $GITHUB_OUTPUT
          else
            echo "overall_status=failure" >> $GITHUB_OUTPUT
            echo "badge_status=failing" >> $GITHUB_OUTPUT
            exit 1
          fi
      - name: Generate test results JSON
        if: always()
        run: |
          mkdir -p test-results
          
          cat > test-results/bonjour.json << EOF
          {
            "schema_version": "1.0",
            "package": {
              "name": "Bonjour",
              "version": "${{ steps.version.outputs.version }}",
              "language": "Networking",
              "category": "Networking"
            },
            "run": {
              "id": "${{ github.run_id }}",
              "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}?job=${{ github.job }}",
              "timestamp": "${{ steps.metadata.outputs.timestamp }}",
              "status": "${{ steps.summary.outputs.overall_status }}",
              "runner": {
                "os": "ubuntu-24.04",
                "arch": "arm64"
              }
            },
            "tests": {
              "passed": ${{ steps.summary.outputs.passed }},
              "failed": ${{ steps.summary.outputs.failed }},
              "skipped": 0,
              "duration_seconds": ${{ steps.summary.outputs.duration }},
              "details": [
                {
                  "name": "Check compatibility headers",
                  "status": "${{ steps.test1.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test1.outputs.duration || 0 }}
                },
                {
                  "name": "Check avahi-utils binary",
                  "status": "${{ steps.test2.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test2.outputs.duration || 0 }}
                },
                {
                  "name": "Check avahi-browse help output",
                  "status": "${{ steps.test3.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test3.outputs.duration || 0 }}
                },
                {
                  "name": "Architecture Verification",
                  "status": "${{ steps.test4.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test4.outputs.duration || 0 }}
                },
                {
                  "name": "Functional Validation",
                  "status": "${{ steps.test5.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test5.outputs.duration || 0 }}
                }
              ]
            },
            "metadata": {
              "dashboard_link": "${{ steps.metadata.outputs.dashboard_link }}",
              "badge_status": "${{ steps.summary.outputs.badge_status }}"
            }
          }
          EOF
          
          echo "Generated test results:"
          cat test-results/bonjour.json
      
      # ============================================================
      # STANDARD STEPS - Usually don't need to modify below here
      # ============================================================
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bonjour-test-results
          path: test-results/bonjour.json
          retention-days: 90
      
      - name: Create test summary
        if: always()
        run: |
          echo "## Bonjour Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Version:** ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ steps.summary.outputs.overall_status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests Passed:** ${{ steps.summary.outputs.passed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests Failed:** ${{ steps.summary.outputs.failed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration:** ${{ steps.summary.outputs.duration }}s" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner:** ubuntu-24.04 (arm64)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Details" >> $GITHUB_STEP_SUMMARY
          echo "1. Check bonjour binary exists: ${{ steps.test1.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "2. Check bonjour version command: ${{ steps.test2.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "3. Check bonjour help output: ${{ steps.test3.outputs.status }}" >> $GITHUB_STEP_SUMMARY

          echo "4. Test 4 - Architecture Verification: ${{ steps.test4.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "5. Test 5 - Functional Validation: ${{ steps.test5.outputs.status }}" >> $GITHUB_STEP_SUMMARY






