name: Test Google Benchmark on Arm64

on:
  workflow_dispatch:
  push:
    branches:
      - main
      - smoke_tests
    paths:
      - 'content/opensource_packages/benchmark.md'
      - '.github/workflows/test-benchmark.yml'

jobs:
  test-benchmark:
    runs-on: ubuntu-24.04-arm
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set test metadata
        id: metadata
        run: |
          echo "timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_OUTPUT
          echo "package_slug=benchmark" >> $GITHUB_OUTPUT
          echo "dashboard_link=/opensource_packages/benchmark" >> $GITHUB_OUTPUT
      
      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential cmake git
      
      - name: Install Google Benchmark
        id: install
        run: |
          echo "Installing Google Benchmark..."
          
          # Clone stable version (v1.8.3 is recent stable)
          git clone --branch v1.8.3 --depth 1 https://github.com/google/benchmark.git
          
          cd benchmark
          cmake -E make_directory "build"
          cmake -E chdir "build" cmake -DBENCHMARK_DOWNLOAD_DEPENDENCIES=on -DCMAKE_BUILD_TYPE=Release ../
          cmake --build "build" --config Release
          sudo cmake --build "build" --config Release --target install
          
          if [ -f "/usr/local/lib/libbenchmark.a" ] || [ -f "/usr/local/lib/libbenchmark.so" ]; then
             echo "Google Benchmark installed successfully"
             echo "install_status=success" >> $GITHUB_OUTPUT
          else
             echo "Google Benchmark installation failed"
             echo "install_status=failed" >> $GITHUB_OUTPUT
             exit 1
          fi
      
      - name: Get Benchmark version
        id: version
        run: |
          # Version is v1.8.3 as pinned
          echo "version=1.8.3" >> $GITHUB_OUTPUT
          echo "Detected Benchmark version: 1.8.3"
      
      - name: Test 1 - Check Headers
        id: test1
        run: |
          START_TIME=$(date +%s)
          
          if [ -f "/usr/local/include/benchmark/benchmark.h" ]; then
            echo "✓ benchmark.h found"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ benchmark.h not found"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT
      
      - name: Test 2 - Compile Simple Benchmark
        id: test2
        run: |
          START_TIME=$(date +%s)
          
          cat > my_benchmark.cc << EOF
          #include <benchmark/benchmark.h>
          
          static void BM_StringCreation(benchmark::State& state) {
            for (auto _ : state)
              std::string empty_string;
          }
          // Register the function as a benchmark
          BENCHMARK(BM_StringCreation);
          
          BENCHMARK_MAIN();
          EOF
          
          # Compile linking against benchmark and pthread
          if g++ my_benchmark.cc -std=c++11 -isystem /usr/local/include -L/usr/local/lib -lbenchmark -lpthread -o my_benchmark; then
             echo "✓ Compilation passed"
             echo "status=passed" >> $GITHUB_OUTPUT
          else
             echo "✗ Compilation failed"
             echo "status=failed" >> $GITHUB_OUTPUT
             exit 1
          fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT
      
      - name: Test 3 - Run Benchmark
        id: test3
        run: |
          START_TIME=$(date +%s)
          
          if ./my_benchmark; then
             echo "✓ Benchmark ran successfully"
             echo "status=passed" >> $GITHUB_OUTPUT
          else
             echo "✗ Benchmark execution failed"
             echo "status=failed" >> $GITHUB_OUTPUT
             exit 1
          fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT

      - name: Calculate test summary
        if: always()
        id: summary
        run: |
          PASSED=0
          FAILED=0
          TOTAL_DURATION=0
          
          process_test() {
            local status=$1
            local duration=$2
            if [ "$status" == "passed" ]; then
              PASSED=$((PASSED + 1))
            elif [ "$status" == "failed" ]; then
              FAILED=$((FAILED + 1))
            fi
            TOTAL_DURATION=$((TOTAL_DURATION + duration))
          }
          
          process_test "${{ steps.test1.outputs.status }}" "${{ steps.test1.outputs.duration || 0 }}"
          process_test "${{ steps.test2.outputs.status }}" "${{ steps.test2.outputs.duration || 0 }}"
          process_test "${{ steps.test3.outputs.status }}" "${{ steps.test3.outputs.duration || 0 }}"
          
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "duration=$TOTAL_DURATION" >> $GITHUB_OUTPUT
          
          if [ $FAILED -eq 0 ]; then
            echo "overall_status=success" >> $GITHUB_OUTPUT
            echo "badge_status=passing" >> $GITHUB_OUTPUT
          else
            echo "overall_status=failure" >> $GITHUB_OUTPUT
            echo "badge_status=failing" >> $GITHUB_OUTPUT
          fi
      
      - name: Generate test results JSON
        if: always()
        run: |
          mkdir -p test-results
          
          cat > test-results/benchmark.json << EOF
          {
            "schema_version": "1.0",
            "package": {
              "name": "Google Benchmark",
              "version": "${{ steps.version.outputs.version }}",
              "language": "C++",
              "category": "Development"
            },
            "run": {
              "id": "${{ github.run_id }}",
              "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
              "timestamp": "${{ steps.metadata.outputs.timestamp }}",
              "status": "${{ steps.summary.outputs.overall_status }}",
              "runner": {
                "os": "ubuntu-24.04",
                "arch": "arm64"
              }
            },
            "tests": {
              "passed": ${{ steps.summary.outputs.passed }},
              "failed": ${{ steps.summary.outputs.failed }},
              "skipped": 0,
              "duration_seconds": ${{ steps.summary.outputs.duration }},
              "details": [
                {
                  "name": "Check Headers",
                  "status": "${{ steps.test1.outputs.status }}",
                  "duration_seconds": ${{ steps.test1.outputs.duration || 0 }}
                },
                {
                  "name": "Compile Simple Benchmark",
                  "status": "${{ steps.test2.outputs.status }}",
                  "duration_seconds": ${{ steps.test2.outputs.duration || 0 }}
                },
                {
                  "name": "Run Benchmark",
                  "status": "${{ steps.test3.outputs.status }}",
                  "duration_seconds": ${{ steps.test3.outputs.duration || 0 }}
                }
              ]
            },
            "metadata": {
              "dashboard_link": "${{ steps.metadata.outputs.dashboard_link }}",
              "badge_status": "${{ steps.summary.outputs.badge_status }}"
            }
          }
          EOF
          
          echo "Generated test results:"
          cat test-results/benchmark.json
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-test-results
          path: test-results/benchmark.json
          retention-days: 90
      
      - name: Commit test results to repository
        if: always() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/smoke_tests')
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          mkdir -p data/test-results
          cp test-results/benchmark.json data/test-results/benchmark.json
          
          git add data/test-results/benchmark.json
          
          if ! git diff --staged --quiet; then
            git commit -m "Update Google Benchmark test results [skip ci]"
            for i in {1..5}; do
              if git pull --rebase origin ${{ github.ref_name }}; then
                if git push; then
                  echo "Successfully pushed test results"
                  break
                fi
              else
                echo "Rebase failed, resolving conflicts..."
                git checkout --ours data/test-results/benchmark.json
                git add data/test-results/benchmark.json
                git rebase --continue || true
              fi
              sleep $((i * 2))
            done
          else
            echo "No changes to commit"
          fi
      
      - name: Create test summary
        if: always()
        run: |
          echo "## Google Benchmark Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Version:** ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ steps.summary.outputs.overall_status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests Passed:** ${{ steps.summary.outputs.passed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests Failed:** ${{ steps.summary.outputs.failed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration:** ${{ steps.summary.outputs.duration }}s" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner:** ubuntu-24.04 (arm64)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Details" >> $GITHUB_STEP_SUMMARY
          echo "1. Check Headers: ${{ steps.test1.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "2. Compile Simple Benchmark: ${{ steps.test2.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "3. Run Benchmark: ${{ steps.test3.outputs.status }}" >> $GITHUB_STEP_SUMMARY
