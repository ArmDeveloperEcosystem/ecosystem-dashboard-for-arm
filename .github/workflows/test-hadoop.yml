name: Test Hadoop on Arm64
on:
  workflow_call:
  push:
    branches:
      - main
      - smoke_tests
    paths:
      - 'content/opensource_packages/hadoop.md'
      - '.github/workflows/test-hadoop.yml'
jobs:
  test-hadoop:
    runs-on: ubuntu-24.04-arm
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set test metadata
        id: metadata
        run: |
          echo "timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_OUTPUT
          echo "package_slug=hadoop" >> $GITHUB_OUTPUT
          echo "dashboard_link=/opensource_packages/hadoop" >> $GITHUB_OUTPUT

      # ============================================================
      # CUSTOMIZE THIS: Install your package
      # ============================================================
      - name: Install Hadoop
        id: install
        run: |
          echo "Installing Hadoop..."
          
          # Install Java (required)
          sudo apt-get update
          sudo apt-get install -y openjdk-11-jdk wget tar
          
          # Download Hadoop binary
          # Using a stable version, e.g., 3.4.0
          VERSION="3.4.0"
          URL="https://downloads.apache.org/hadoop/common/hadoop-${VERSION}/hadoop-${VERSION}.tar.gz"
          
          wget -q $URL -O hadoop.tar.gz
          
          # Extract
          sudo tar -xzf hadoop.tar.gz -C /opt
          sudo mv /opt/hadoop-${VERSION} /opt/hadoop
          
          # Set environment variables
          echo "JAVA_HOME=/usr/lib/jvm/java-11-openjdk-arm64" >> $GITHUB_ENV
          echo "HADOOP_HOME=/opt/hadoop" >> $GITHUB_ENV
          echo "/opt/hadoop/bin" >> $GITHUB_PATH
          echo "/opt/hadoop/sbin" >> $GITHUB_PATH
          
          # Configure JAVA_HOME in hadoop-env.sh
          # This is critical for Hadoop to find Java
          echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-arm64" | sudo tee -a /opt/hadoop/etc/hadoop/hadoop-env.sh
          
          # Verify installation
          if [ -d "/opt/hadoop/bin" ]; then
             echo "Hadoop installed successfully"
             echo "install_status=success" >> $GITHUB_OUTPUT
          else
             echo "Hadoop installation failed"
             echo "install_status=failed" >> $GITHUB_OUTPUT
             exit 1
          fi

      # ============================================================
      # CUSTOMIZE THIS: Get the package version
      # ============================================================
      - name: Get Hadoop version
        id: version
        run: |
          # Get version from hadoop command
          # We need to ensure environment variables are set for this step too (GITHUB_ENV applies to next steps)
          export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-arm64
          export HADOOP_HOME=/opt/hadoop
          export PATH=$PATH:/opt/hadoop/bin
          
          VERSION=$(hadoop version | head -n 1 | awk '{print $2}' || echo "unknown")
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "Detected Hadoop version: $VERSION"

      # ============================================================
      # ADD YOUR TESTS BELOW
      # Each test should:
      # 1. Have a unique id (test1, test2, etc.)
      # 2. Track start/end time for duration
      # 3. Set status=passed or status=failed
      # 4. Exit 1 on failure
      # ============================================================

      - name: Test 1 - Check hadoop binary exists
        id: test1
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          if command -v hadoop &> /dev/null; then
            echo "✓ hadoop binary found"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ hadoop binary not found"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
            fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT

      - name: Test 2 - Check hadoop version command
        id: test2
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          if hadoop version | grep -q "Hadoop"; then
            echo "✓ hadoop version command works"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ hadoop version command failed"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
            fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT

      - name: Test 3 - Check hdfs binary exists
        id: test3
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          if command -v hdfs &> /dev/null; then
            echo "✓ hdfs binary found"
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "✗ hdfs binary not found"
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
            fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT

      - name: Test 4 - Run Hadoop MapReduce example (grep)
        id: test4
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          # Create input directory and files
          mkdir input
          cp /opt/hadoop/etc/hadoop/*.xml input
          
          # Run the grep example (standalone mode)
          # This runs locally without starting HDFS/YARN daemons
          if hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output 'dfs[a-z.]+'; then
             echo "✓ MapReduce example passed"
             if [ -f "output/_SUCCESS" ]; then
                echo "✓ Output generated"
                echo "status=passed" >> $GITHUB_OUTPUT
            else
                echo "✗ Output not generated"
                echo "status=failed" >> $GITHUB_OUTPUT
                exit 1
            fi
          else
             echo "✗ MapReduce example failed"
             echo "status=failed" >> $GITHUB_OUTPUT
             exit 1
            fi
          
          # Cleanup
          rm -rf input output
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT

      - name: Test 5 - Check native library loading
        id: test5
        continue-on-error: true
        run: |
          START_TIME=$(date +%s)
          
          # Check if native libraries are loaded (optional, but good for ARM64 verification)
          if hadoop checknative -a | grep -q "Native library checking"; then
             echo "✓ Native library check ran"
             # We don't fail if some libs are missing (like snappy/zstd) unless critical
             # But we want to see if libhadoop was loaded.
             if hadoop checknative -a | grep -q "hadoop:  true"; then
                echo "✓ libhadoop loaded"
            else
                echo "⚠ libhadoop not loaded (might be expected if not compiled for this specific ARM64 env, but Java fallback works)"
            fi
             echo "status=passed" >> $GITHUB_OUTPUT
          else
             echo "✗ Native library check failed"
             echo "status=failed" >> $GITHUB_OUTPUT
             exit 1
            fi
          
          END_TIME=$(date +%s)
          echo "duration=$((END_TIME - START_TIME))" >> $GITHUB_OUTPUT

            # ============================================================
      # UPDATE THIS: Calculate summary based on your number of tests
      # Add/remove test result checks to match your tests above
      - name: Calculate test summary
        if: always()
        id: summary
        run: |
          PASSED=0
          FAILED=0
          TOTAL_DURATION=0

          # Check hadoop binary exists
          if [ "${{ steps.test1.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test1.outputs.duration || 0 }}))

          # Check hadoop version command
          if [ "${{ steps.test2.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test2.outputs.duration || 0 }}))

          # Check hdfs binary exists
          if [ "${{ steps.test3.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test3.outputs.duration || 0 }}))

          # Run Hadoop MapReduce example (grep)
          if [ "${{ steps.test4.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test4.outputs.duration || 0 }}))

          # Check native library loading
          if [ "${{ steps.test5.outputs.status }}" == "passed" ]; then
            PASSED=$((PASSED + 1))
          else
            FAILED=$((FAILED + 1))
          fi
          TOTAL_DURATION=$((TOTAL_DURATION + ${{ steps.test5.outputs.duration || 0 }}))

          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "duration=$TOTAL_DURATION" >> $GITHUB_OUTPUT

          if [ $FAILED -eq 0 ]; then
            echo "overall_status=success" >> $GITHUB_OUTPUT
            echo "badge_status=passing" >> $GITHUB_OUTPUT
          else
            echo "overall_status=failure" >> $GITHUB_OUTPUT
            echo "badge_status=failing" >> $GITHUB_OUTPUT
            exit 1
          fi
      - name: Generate test results JSON
        if: always()
        run: |
          mkdir -p test-results
          
          cat > test-results/hadoop.json << EOF
          {
            "schema_version": "1.0",
            "package": {
              "name": "Hadoop",
              "version": "${{ steps.version.outputs.version }}",
              "language": "REPLACE_ME",
              "category": "REPLACE_ME"
            },
            "run": {
              "id": "${{ github.run_id }}",
              "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}?job=${{ github.job }}",
              "timestamp": "${{ steps.metadata.outputs.timestamp }}",
              "status": "${{ steps.summary.outputs.overall_status }}",
              "runner": {
                "os": "ubuntu-24.04",
                "arch": "arm64"
              }
            },
            "tests": {
              "passed": ${{ steps.summary.outputs.passed }},
              "failed": ${{ steps.summary.outputs.failed }},
              "skipped": 0,
              "duration_seconds": ${{ steps.summary.outputs.duration || 0 }},
              "details": [
                {
                  "name": "Check hadoop binary exists",
                  "status": "${{ steps.test1.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test1.outputs.duration || 0 }}
                },
                {
                  "name": "Check hadoop version command",
                  "status": "${{ steps.test2.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test2.outputs.duration || 0 }}
                },
                {
                  "name": "Check hdfs binary exists",
                  "status": "${{ steps.test3.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test3.outputs.duration || 0 }}
                },
                {
                  "name": "Run Hadoop MapReduce example (grep)",
                  "status": "${{ steps.test4.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test4.outputs.duration || 0 }}
                },
                {
                  "name": "Check native library loading",
                  "status": "${{ steps.test5.outputs.status || 'skipped' }}",
                  "duration_seconds": ${{ steps.test5.outputs.duration || 0 }}
                }
              ]
            },
            "metadata": {
              "dashboard_link": "${{ steps.metadata.outputs.dashboard_link }}",
              "badge_status": "${{ steps.summary.outputs.badge_status }}"
            }
          }
          EOF
          
          echo "Generated test results:"
          cat test-results/hadoop.json
      # ============================================================
      # STANDARD STEPS - Usually don't need to modify below here
      # ============================================================
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: hadoop-test-results
          path: test-results/hadoop.json
          retention-days: 90
      
      - name: Create test summary
        if: always()
        run: |
          echo "## Hadoop Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Version:** ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ steps.summary.outputs.overall_status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests Passed:** ${{ steps.summary.outputs.passed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests Failed:** ${{ steps.summary.outputs.failed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration:** ${{ steps.summary.outputs.duration || 0 }}s" >> $GITHUB_STEP_SUMMARY
          echo "- **Runner:** ubuntu-24.04 (arm64)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Details" >> $GITHUB_STEP_SUMMARY
          echo "1. Test 1 - Check hadoop binary exists: ${{ steps.test1.outputs.status || 'skipped' }}" >> $GITHUB_STEP_SUMMARY
          echo "2. Test 2 - Check hadoop version command: ${{ steps.test2.outputs.status || 'skipped' }}" >> $GITHUB_STEP_SUMMARY
          echo "3. Test 3 - Check hdfs binary exists: ${{ steps.test3.outputs.status || 'skipped' }}" >> $GITHUB_STEP_SUMMARY
          echo "4. Test 4 - Run Hadoop MapReduce example (grep): ${{ steps.test4.outputs.status || 'skipped' }}" >> $GITHUB_STEP_SUMMARY
          echo "5. Test 5 - Check native library loading: ${{ steps.test5.outputs.status || 'skipped' }}" >> $GITHUB_STEP_SUMMARY



