---
name: Ampere Optimized Ollama
category: AI/ML
description: Ampere Optimized Ollama is an optimized build of Ollama designed to efficiently run and serve large language models on Ampere CPUs, delivering improved inference performance through architecture-specific optimizations and support for custom quantized models.
download_url: https://hub.docker.com/r/amperecomputingai/ollama/tags
works_on_arm: true
supported_minimum_version:
    version_number: 1.0.0-ol9
    release_date: 2025/07/26
 
 
optional_info:
    homepage_url: https://hub.docker.com/r/amperecomputingai/ollama
    support_caveats: The [Docker image for Ollama by Ampere Computing](https://hub.docker.com/r/amperecomputingai/ollama/tags) can be run on bare metal Ampere CPUs and Ampere-based VMs available in the cloud.
    alternative_options:
    getting_started_resources:
        official_docs: https://hub.docker.com/r/amperecomputingai/ollama#running
        arm_content:
        partner_content:
    arm_recommended_minimum_version:
        version_number:
        release_date:
        reference_content:
        rationale:
 
optional_hidden_info:
    release_notes__supported_minimum:
    release_notes__recommended_minimum:
    other_info: The release notes specific to Linux/Arm64 support isn't available. Linux/Arm64 Ollama docker images by Ampere Computing are available from version 1.0.0-ol9 onwards.
 
---

