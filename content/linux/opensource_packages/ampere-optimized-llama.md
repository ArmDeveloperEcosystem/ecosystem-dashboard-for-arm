---
name: Ampere Optimized Llama.cpp
category: AI/ML
description: Ampere Optimized llama.cpp is an optimized build of llama.cpp designed to run GGUF large language models efficiently on Ampere CPUs, providing improved inference performance through architecture-specific optimizations.
download_url: https://github.com/AmpereComputingAI/llama.cpp/releases
works_on_arm: true
supported_minimum_version:
    version_number: 1.2.0
    release_date: 2024/05/16
 
 
optional_info:
    homepage_url: https://github.com/AmpereComputingAI/llama.cpp
    support_caveats: The [Docker image for llama.cpp by Ampere Computing](https://hub.docker.com/r/amperecomputingai/llama.cpp/tags) can be run on bare metal Ampere CPUs and Ampere-based VMs available in the cloud.
    alternative_options:
    getting_started_resources:
        official_docs: https://github.com/AmpereComputingAI/llama.cpp#starting-container
        arm_content:
        partner_content:
    arm_recommended_minimum_version:
        version_number:
        release_date:
        reference_content:
        rationale:
 
optional_hidden_info:
    release_notes__supported_minimum:
    release_notes__recommended_minimum:
    other_info: The release notes specific to Linux/Arm64 support isn't available. Linux/Arm64/v8 Llama.cpp docker images by Ampere Computing are available from version 1.2.0 onwards.
 
---
