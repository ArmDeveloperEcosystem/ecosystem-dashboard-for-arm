---
name: vLLM
category: AI/ML
description: vLLM is a fast, straightforward library for LLM inference and serving.
download_url: https://github.com/vllm-project/vllm/releases
works_on_arm: true
supported_minimum_version:
    version_number: 0.6.5
    release_date: 2024/12/17


optional_info:
    homepage_url: https://github.com/vllm-project/vllm/
    support_caveats:
    alternative_options:
    getting_started_resources:
        official_docs: https://github.com/vllm-project/vllm/
        arm_content: https://learn.arm.com/learning-paths/servers-and-cloud-computing/vllm/
        partner_content:
    arm_recommended_minimum_version:
        version_number:
        release_date:
        reference_content:
        rationale:


optional_hidden_info:
    release_notes__supported_minimum:
    release_notes__recommended_minimum:
    other_info: 

---
